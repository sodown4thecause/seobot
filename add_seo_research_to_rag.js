const fs = require('fs');

// Read the SEO research document
const filePath = 'SEO_AEO Chatbot RAG Content Research.md';
const content = fs.readFileSync(filePath, 'utf8');

// Split content into logical chunks based on sections
function chunkContent(text) {
  const chunks = [];
  
  // Split by main sections (##)
  const sections = text.split(/(?=## \*\*\d+)/);
  
  sections.forEach((section, index) => {
    const lines = section.split('\n');
    const title = lines.find(line => line.startsWith('##'))?.replace(/[#*]/g, '').trim() || `SEO Research Section ${index + 1}`;
    
    // For very long sections, split further by subsections (###)
    if (section.length > 4000) {
      const subsections = section.split(/(?=### \*\*)/);
      
      subsections.forEach((subsection, subIndex) => {
        if (subsection.trim()) {
          const subTitle = subsection.split('\n').find(line => line.startsWith('###'))?.replace(/[#*]/g, '').trim();
          const chunkTitle = subTitle ? `${title} - ${subTitle}` : `${title} (Part ${subIndex + 1})`;
          
          chunks.push({
            title: chunkTitle,
            content: subsection.trim(),
            agent_type: 'content_writer'
          });
        }
      });
    } else if (section.trim()) {
      chunks.push({
        title: title,
        content: section.trim(),
        agent_type: 'content_writer'
      });
    }
  });
  
  return chunks;
}

const chunks = chunkContent(content);

// Generate SQL INSERT statements
let sql = `-- SEO/AEO Research Document Chunks for RAG\n-- This provides the content_writer agent with comprehensive SEO knowledge\n\n`;

chunks.forEach((chunk, index) => {
  const escapedTitle = chunk.title.replace(/'/g, "''");
  const escapedContent = chunk.content.replace(/'/g, "''");
  
  sql += `-- Chunk ${index + 1}: ${chunk.title}\n`;
  sql += `INSERT INTO agent_documents (title, content, agent_type, embedding)\n`;
  sql += `VALUES (\n`;
  sql += `  '${escapedTitle}',\n`;
  sql += `  '${escapedContent}',\n`;
  sql += `  '${chunk.agent_type}',\n`;
  sql += `  NULL  -- Embedding will be generated by the system\n`;
  sql += `);\n\n`;
});

// Add summary chunk
sql += `-- Summary chunk with key takeaways\n`;
sql += `INSERT INTO agent_documents (title, content, agent_type, embedding)\n`;
sql += `VALUES (\n`;
sql += `  'SEO/AEO Research Summary - Key Optimization Principles',\n`;
sql += `  'CRITICAL SEO/AEO PRINCIPLES FOR CONTENT WRITING:\n\n`;
sql += `1. E-E-A-T Framework: Experience, Expertise, Authoritativeness, Trustworthiness - with Experience being the hardest for AI to fake\n`;
sql += `2. "Fully Meets" Standard: Content must answer the query completely in the first paragraph (Inverted Pyramid)\n`;
sql += `3. Entity Salience: Target entity must have >0.30 Entity Salience Ratio (ESR) - 30% of semantic weight\n`;
sql += `4. Schema Implementation: FAQPage and Article schema with mentions property for disambiguation\n`;
sql += `5. AI Detection Avoidance: Avoid words like "delve, robust, tapestry, seamless" - aim for <20% AI probability\n`;
sql += `6. Intent Matching: Target "Problem Solving" queries (70%+ AIO visibility) over broad research terms\n`;
sql += `7. Freshness Signals: Update lastmod tags in XML sitemaps for Bing Deep Search inclusion\n`;
sql += `8. Information Gain: Provide unique insights, not consensus summaries\n`;
sql += `9. Burstiness: Vary sentence length and structure to increase human-like rhythm\n`;
sql += `10. Trust Signals: Clear authorship, contact info, transparent sourcing for YMYL content',\n`;
sql += `  'content_writer',\n`;
sql += `  NULL\n`;
sql += `);\n\n`;

// Write to file
fs.writeFileSync('seo_research_chunks.sql', sql);

console.log(`Generated ${chunks.length + 1} chunks for SEO research document`);
console.log('SQL file saved as: seo_research_chunks.sql');
console.log('\nChunk titles:');
chunks.forEach((chunk, index) => {
  console.log(`${index + 1}. ${chunk.title}`);
});